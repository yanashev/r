---
title: "Лабораторная работа №2"
author: "Шевцова Я.А."
date: "`r format(Sys.Date(), '%d  %B  %Y')`"
output:  
  word_document: 
    reference_docx: word_styles.docx
---

```{r setup, include=FALSE}
library(Hmisc)
library(knitr)
library(pander)
knitr::opts_chunk$set(echo = FALSE)
```

# Лабораторная работа №2
Во второй лабораторной работе продолжим работу с примером данных, использовавшихся в предыдущей работе.
Оценим параметры моделей, объясняющих поведение данного показателя несколькими факторами.

## Зависимая переменная модели:

* `Y` *OOT_2012* - Объем отгруженных товаров собственного производства, выполненных работ и услуг собственными силами по видам экономической деятельности: обрабатывающие производства

## Независимые переменные модели:

* `X1` *IP_2012* - Индексы цен производителей промышленных товаров по видам экономической деятельности: обрабатывающие производства

* `X2` *IAP_2012* - Изменение среднегодовой численности занятых

* `X3` *IPHV_2011* -Индекс физического объема ВРП

* `X4` *SUMD_2011* - Сумма убытка организаций по отдельным видам экономической деятельности: обрабатывающие производства


```{r, import, echo = FALSE}
load('Labs_Shevtsova_data.RData') #Импортируем данные из рабочего пространства, созданного в конце прошлой лаборатоной
```
```{r}
#Нумерация таблиц
table.num <- 1;
```
## Исходная модель:

$Y = \beta_0 +\beta_1 X1 + \beta_2 X2  + \beta_3 X3 +  + \beta_4 X4$

## Выполним оценку параметров модели линейной регрессии
#### Таблица № `r table.num `

```{r, echo = FALSE} 
#Оценка параметров модели линейной регрессии
fit.1 <- lm(OOT_2012 ~ IP_2012 + IAP_2012 + IPHV_2011 + SUMD_2011, data = reg.df)
table.num <- table.num +1
kable(round(summary(fit.1)$coef,4))
```

## Исколючаем из модели наименее значимый фактор IAP_2012
#### Таблица № `r table.num `
```{r, echo = FALSE}
#Исколючаем из модели наименее значимый фактор RDD.2014
fit.2 <- lm(OOT_2012 ~ IP_2012 + IPHV_2011 + SUMD_2011, data = reg.df)
table.num <- table.num +1
kable(round(summary(fit.2)$coef,4)) #Только таблица с коэффициентами
```

## Исколючаем из модели наименее значимый фактор IP_2012
#### Таблица № `r table.num `
```{r, echo = FALSE}
#Исколючаем из модели наименее значимый фактор RDD.2014
fit.3 <- lm(OOT_2012 ~ IPHV_2011 + SUMD_2011, data = reg.df)
table.num <- table.num +1
kable(round(summary(fit.3)$coef,4)) #Только таблица с коэффициентами
```

## Исколючаем из модели наименее значимый фактор IPHV_2011
#### Таблица № `r table.num `
```{r, echo = FALSE}
#Исколючаем из модели наименее значимый фактор RDD.2014
fit.4 <- lm(OOT_2012 ~ SUMD_2011, data = reg.df)
table.num <- table.num +1
kable(round(summary(fit.4)$coef,4)) #Только таблица с коэффициентами
```

## Включим в модель фиктивные переменные
#### Таблица № `r table.num `
```{r, echo = FALSE}
#Модель с переменной структурой
fit.X1.fo <- lm(OOT_2012 ~ SUMD_2011*FO, data = reg.df)
table.num <- table.num +1
kable(round(summary(fit.X1.fo)$coef,4))
```




```{r, echo = FALSE}
#Создаем фрейм со всеми переменными-факторами (создаем фиктивные)
X.matrix <- model.matrix(OOT_2012 ~ SUMD_2011*FO, data = reg.df)
#Присоединяем независимую переменную
data.fit <- cbind(OOT_2012 = reg.df$OOT_2012, data.frame(X.matrix)[, -1])
```

## Воспользуемся пользовательской функцией для исключения незначимых параметров
### Сравним методы применения данной функции
### Метод Бонферрони:
#### Таблица № `r table.num `
```{r, echo = FALSE}
source('https://raw.githubusercontent.com/aksyuk/R-Practice-basics/master/user_functions/removeFactorsByPValue.R') #Функция с последовательным исключением аномальных
#доводим до значимости
table.num <- table.num +1
fit.X1.fo1 <- removeFactorsByPValue(data = data.fit, y.var.name = 'OOT_2012', p.adj.method = 'bonferroni')
kable(round(summary(fit.X1.fo1)$coef, 4))
pander(list('Доля дисперсии', summary(fit.X1.fo1)$adj.r.squared))
```

### Исключение параметров без поправки:
#### Таблица № `r table.num `
```{r, echo = FALSE}
#доводим до значимости
fit.X1.fo2 <- removeFactorsByPValue(data = data.fit, y.var.name = 'OOT_2012')
kable(round(summary(fit.X1.fo2)$coef, 4))
pander(list('Доля дисперсии', summary(fit.X1.fo2)$adj.r.squared))
table.num <- table.num +1
```



## Составим таблицу характеристик качества построенных моделей
#### Таблица № `r table.num `
```{r, echo = FALSE}
#Составим таблицу характеристик качества построенных моделей
models.list <- list(fit.4, fit.X1.fo, fit.X1.fo1, fit.X1.fo2)
names(models.list) <- c('fit.4', 'fit.X1.fo', 'fit.X1.fo1', 'fit.X1.fo2')
df.goodones.of.fit <- data.frame(Модель = names(models.list),
                                 R.2.скорр = rep(0, length(models.list)),
                                 F.расч = rep(0,length(models.list)),
                                 Станд.Ошибка = rep(0,length(models.list)))

for (i in 1:length(models.list)){
  df.goodones.of.fit[i,'R.2.скорр'] <- round(summary(models.list[[i]])$adj.r.squared, 3) #Скорректированный R-квадрат
  df.goodones.of.fit[i,'F.расч'] <- round(summary(models.list[[i]])$fstatistic[1], 2) #F-расчетное
  df.goodones.of.fit[i,'Станд.Ошибка'] <- round(summary(models.list[[i]])$sigma, 1) #Стандартная ошибка
}

kable(df.goodones.of.fit)
table.num <- table.num +1
```
Больше всего подходит четвертая модель:

Явный вид модели $OOT2012 = 54589.2205 +59.9148*SUMD2011 - 188734.2435*FOСЗФО + 52.7608*SUMD2011.FOСЗФО$

# Проделаем аналогичную работу над логарифмированными данными:

```{r, echo = FALSE}
reg.df1 <- cbind(reg.df$FO,log(reg.df[,2:6]))
colnames(reg.df1)<- colnames(reg.df)
```

## Выполним оценку параметров модели линейной регрессии
#### Таблица № `r table.num `
```{r, echo = FALSE} 
#Оценка параметров модели линейной регрессии
fit.1log <- lm(OOT_2012 ~ IP_2012 + IAP_2012 + IPHV_2011 + SUMD_2011, data = reg.df1)
kable(round(summary(fit.1log)$coef,4))
table.num <- table.num +1
```

## Исколючаем из модели наименее значимый фактор IIK.2013
#### Таблица № `r table.num `
```{r, echo = FALSE}
#Исколючаем из модели наименее значимый фактор IIK.2013
fit.2log <- lm(OOT_2012 ~  IAP_2012 + IPHV_2011 + SUMD_2011, data = reg.df1)
kable(round(summary(fit.2log)$coef,4)) #Только таблица с коэффициентами
table.num <- table.num +1
```
## Исколючаем из модели наименее значимый фактор IAP_2012
#### Таблица № `r table.num `
```{r, echo = FALSE}
#Исколючаем из модели наименее значимый фактор IIK.2013
fit.3log <- lm(OOT_2012 ~  IPHV_2011 + SUMD_2011, data = reg.df1)
kable(round(summary(fit.3log)$coef,4)) #Только таблица с коэффициентами
table.num <- table.num +1
```

## Включим в модель фиктивные переменные
#### Таблица № `r table.num `
```{r, echo = FALSE}
#Модель с переменной структурой
fit.X1log.fo <- lm(OOT_2012 ~  IPHV_2011*FO + SUMD_2011*FO, data = reg.df1)
kable(round(summary(fit.X1log.fo)$coef,4))
table.num <- table.num +1
```

```{r, echo = FALSE}
#Создаем фрейм со всеми переменными-факторами (создаем фиктивные)
X.matrix.log <- model.matrix(OOT_2012 ~  IPHV_2011*FO + SUMD_2011*FO, data = reg.df1)
#Присоединяем независимую переменную
data.fit.log <- cbind(OOT_2012 = reg.df1$OOT_2012, data.frame(X.matrix.log)[, -1])
```

## Воспользуемся пользовательской функцией для исключения незначимых параметров
### Сравним методы применения данной функции
### Метод Бонферрони:
#### Таблица № `r table.num `
```{r, echo = FALSE}
#доводим до значимости
fit.X1log.fo1 <- removeFactorsByPValue(data = data.fit.log, y.var.name = 'OOT_2012', p.adj.method = 'bonferroni')
kable(round(summary(fit.X1log.fo1)$coef, 4))
pander(list('Доля дисперсии', summary(fit.X1log.fo1)$adj.r.squared))
table.num <- table.num +1
```

### Исключение параметров без поправки:
#### Таблица № `r table.num `
```{r, echo = FALSE}
#доводим до значимости
fit.X1log.fo2 <- removeFactorsByPValue(data = data.fit.log, y.var.name = 'OOT_2012')
kable(round(summary(fit.X1log.fo2)$coef, 4))
pander(list('Доля дисперсии', summary(fit.X1log.fo2)$adj.r.squared))
table.num <- table.num +1
```



## Составим таблицу характеристик качества построенных моделей
#### Таблица № `r table.num `
```{r, echo = FALSE}
#Составим таблицу характеристик качества построенных моделей
models.list.log <- list(fit.4, fit.X1.fo, fit.X1.fo1, fit.X1.fo2, fit.3log, fit.X1log.fo, fit.X1log.fo1, fit.X1log.fo2)
names(models.list.log) <- c('fit.4', 'fit.X1.fo', 'fit.X1.fo1', 'fit.X1.fo2', 'fit.3log', 'fit.X1log.fo', 'fit.X1log.fo1', 'fit.X1log.fo2')
df.goodones.of.fit.log <- data.frame(Модель = names(models.list.log),
                                 R.2.скорр = rep(0, length(models.list.log)),
                                 F.расч = rep(0,length(models.list.log)),
                                 Станд.Ошибка = rep(0,length(models.list.log)))

for (i in 1:length(models.list.log)){
  df.goodones.of.fit.log[i,'R.2.скорр'] <- round(summary(models.list.log[[i]])$adj.r.squared, 3) #Скорректированный R-квадрат
  df.goodones.of.fit.log[i,'F.расч'] <- round(summary(models.list.log[[i]])$fstatistic[1], 2) #F-расчетное
  df.goodones.of.fit.log[i,'Станд.Ошибка'] <- round(summary(models.list.log[[i]])$sigma, 4) #Стандартная ошибка
}

kable(df.goodones.of.fit.log)
```
### Результат: 

По столбцу $R^2$ больше всего подходит последняя модель $R^2=0,852$.

По столбцу F.расч - первая $F=255.17$; 

По столбцу стандартной ошибки - последняя $S=0.6928$ 

Явный вид модели $OOT2012 = -61.2231+14.5167*IPHV2011+1.0094*FOУФО+65.7079*FOЦФО+0.6529*SUMD2011+0.1641*IPHV2011.FOСЗФО-13.9519*IPHV2011.FOЦФО+0.0847*FOПФО.SUMD2011+0.1205*FOСФО.SUMD2011$

```{r, echo = FALSE}
#чистим рабочее пространство
rm(i, df.goodones.of.fit, data.fit, X.matrix, fit.1, fit.2, fit.X1.fo, df.goodones.of.fit.log, data.fit.log, X.matrix.log, fit.1log, fit.2log, fit.X1log.fo, fit.X1log.fo1, fit.X1log.fo2, fit.X1.fo1, fit.X1.fo2, removeFactorsByPValue, table.num,fit.3,fit.3log,fit.4,r.corr,r.corr1,table,W)
```

```{r, echo = FALSE}
#Сохранение рабочего пространства
save.image('labs_ШевцоваЯА_models.RData')
```






